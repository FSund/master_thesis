\chapter{Fractures}

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{images/fracture/large_fracture05}
    \caption{Caption}
\end{figure}

We want to study the behaviour of water trapped in nanoscale (pores and) fractures in silica, so need want a way to generate and characterize such a structure. (Several methods of characterizing a fracture could be imagined (\hl{SOURCES, examples}), and we will use several of them.)        

\hl{terrain == heightmap??, finn bra ord her}

\section{Characterization}

\todo{change wording? copied from Fractals...}
An \emph{affine transformation} transforms a point $\bvec x = (x_1, \dots, x_n)$ into new points $\bvec x' = (r_1x_1, \dots, r_n, x_n)$, where the scaling rations $r_1, \dots, r_n$ are \emph{not} all equal.

A bounded set $\mathcal{S}$ is \emph{self-affine} if $\mathcal{S}$ is the union of $N$ non-overlapping subsets $\mathcal{S}_1, \dots, \mathcal{S}_N$, each of which is congruent to the set $\bvec r(\mathcal{S})$ obtained from $\mathcal S$ by the affine transform defined by $\bvec r$. Here \emph{congruent} means that the set of points $\mathcal{S}$ is identical to the set of points $\bvec r(\mathcal{S})$ after possible translations and/or rotations of the set\cite{feder1988fractals}.

A set $\mathcal{S}$ is \emph{statistically self-affine} if $\mathcal{S}$ is the union of $N$ non-overlapping subsets each of which is scaled down by $\bvec r$ from the original, and is identical in all statistical respects to $\bvec r(\mathcal{S})$.

\subsection{Hurst exponent}
\orangebox{
\begin{itemize}
    \item define fractal dimension
\end{itemize}
}

To characterize a fractal one can use the Hurst exponent, usually called $H$\footnote{\todo[inline]{The name used by Hurst in his work where he first describes the exponent was actually $K$\cite{hurst1965longterm}\cite{hurst1951longterm}}}, which comes from a statistical method developed by Hurst\cite{hurst1965longterm}\cite{hurst1951longterm}. The Hurst exponent is related to the fractal dimension $D$ by
\begin{align*}
    D = d-H,
\end{align*}
where $d$ is the spatial dimension of the fractal's domain\cite{feder1988fractals}.

The statistical method developed by Hurst is called \emph{rescaled range analysis} and was designed for use on 1-dimensional time series $f(t)$. The method has been generalized to higher dimensions\cite{fan2013rescaled}, but the original 1D form is shown here.

\subsubsection{Rescaled range analysis}
First the time series is divided into \todo{overlapping/non-overlapping?} intervals of length $\tau$. The average over each interval of length $\tau$ is
\begin{align*}
    \langle f \rangle_\tau = \frac{1}{\tau} \sum_{t=1}^\tau f(t).
\end{align*}
We let $F$ be the accumulated deviation from the mean
\begin{align*}
    F(t, \tau) = \sum_{t' = 1}^t \big( f(t') - \langle f \rangle_\tau \big).
\end{align*}
The difference between the maximum and minimum of the accumulated deviation from the mean is the \emph{range} R
\begin{align*}
    R(\tau) = \max_{1 \leq t \leq \tau} \big(F(t,\tau)\big) - \min_{1 \leq t \leq \tau} \big(F(t, \tau)\big).
\end{align*}
The standard deviation $S$ of the time series is estimated using
\begin{align*}
    S^2 = \frac{1}{\tau} \sum_{t=1}^\tau \big( f(t) - \langle f \rangle_\tau \big)^2.
\end{align*}
Hurst found that the observed \emph{rescaled range}, $R/S$, for many time series is described by the \hl{empirical} relation\cite{feder1988fractals}
\begin{align*}
    \frac{R}{S} = \left(\frac{\tau}{2}\right)^H \sim \tau^H.
\end{align*}
We now see that we can estimate the Hurst exponent by a linear fit of the form
\begin{align*}
    \log \left(\frac{R}{S}\right) \sim H\log\tau,
\end{align*}
where we find $H$ as the slope of the linear fit.

\todo[inline]{Something about that it's hard to measure, and why.}

\subsubsection{Detrending moving average}
To estimate the Hurst exponent of a surface we use a method called detrending moving average (DMA) first described by E. Alessio, A. Carbone et al.\cite{alessio2002dma}, and later generalized to higher dimensions by A. Carbone \cite{carbone2007algorithm}. We use this method because ??? \todo[inline]{good results, easy to implement? }

We define a \hl(self-affine) surface as $f(i,j)$, where $f$ is the height in the point $(i,j)$, defined in a discrete 2-dimensional domain with size $N\times N$, and with $i,j = 1,\dots,N$. We divide the surface into square \hl{subsurfaces} of size $n \times n$, and find the average $\tilde f_n$ of each subsurface by\footnote{\cref{eq:carbone_average} is how the average $\tilde f_n$ is stated in the article\cite{carbone2007algorithm}, but we rewrite it to \cref{eq:carbone_average_rewritten} so it's easier to understand. The two forms are equivalent.}
\begin{align}
    \tilde f_n(i,j) 
    &= \frac{1}{n^2}\sum_{k=-m}^{n-1-m} ~ \sum_{l=-m}^{n-1-m} f(i-k, j-l) \label{eq:carbone_average}\\
%     &= \frac{1}{n^2}\sum_{k=i-m}^{i-n+1+m}\sum_{l=j-m}^{j-n+1+m} f(i-k, j-l) \\
    &= \frac{1}{n^2} \sum_{k=(i+m)-n+1}^{i+m} ~ \sum_{l=(i+m)-n+1}^{i+m} f(k, l), \label{eq:carbone_average_rewritten}
\end{align}
where
\begin{align*}
    &m = \left \lfloor n\theta \right \rfloor &\text{for }0 \leq \theta < 1,
\end{align*}
which means that $0 \leq m \leq (n-1)$. $\theta$ is a parameter that controls the position of the square relative to the point $(i,j)$ in $\tilde f_n(i,j)$. There are three \hl{extreme} cases for $\theta$, which are listed below, and are illustrated in \cref{fig:DMA_theta}.
% \begin{itemize}
%     \item For $\theta = 0$ we have $m=0$ and we average over a square with the point $(i,j)$ in the square's upper right corner (($i-n+1) \leq k,l \leq i$). See \cref{fig:DMA_theta_a}.
%     \item For $\theta = 1/2$ we average over a square centered on the point $(i,j)$. See \cref{fig:DMA_theta_b}.
%     \item For $\theta = (n-1)/n$ we have the maximum value for $m$, $m=n-1$, and average over a square with the point $(i,j)$ in the square's lower left corner \todo{THESE LIMITS ARE WRONG??}($i \leq k,l \leq (i+n-1)$). See \cref{fig:DMA_theta_c}.
% \end{itemize}
\begin{description}
    \item[$\bm{\theta = 0}$:] \hfill\\ 
        We have $m=0$ and we average over a square with the point $(i,j)$ in the square's upper right corner (($i-n+1) \leq k,l \leq i$). See \cref{fig:DMA_theta_a}.
    \item[$\bm{\theta = 1/2}$:] \hfill\\ 
        We average over a square centered on the point $(i,j)$. See \cref{fig:DMA_theta_b}.
    \item[$\bm{\theta = (n-1)/n}$:] \hfill\\ 
        {\sloppy 
        We have the maximum value for $m$, $m=n-1$, and average over a square with the point $(i,j)$ in the square's lower left corner \todo{\st{THESE LIMITS ARE WRONG??} fixed}\\(${i \leq k,l \leq (i+n-1)}$). See \cref{fig:DMA_theta_c}.
        }
\end{description}

\begin{figure}
    \centering
    \begin{subfigure}[b]{0.25\textwidth}
        \includesvg[width=\textwidth, svgpath=./images/Hurst/]{2DDMA_theta04_a}
%         \caption{Illustration of how to divide a convex hexahedron into five tetraheda.}
        \caption{$\theta = 0$}
        \label{fig:DMA_theta_a}
    \end{subfigure}
    \hspace{0.1\textwidth}
    \begin{subfigure}[b]{0.25\textwidth}
        \includesvg[width=\textwidth, svgpath=./images/Hurst/]{2DDMA_theta04_b}
%         \caption{A random fracture made from two periodic heightmaps.}
        \caption{$\theta = 1/2$}
        \label{fig:DMA_theta_b}
    \end{subfigure}
    \hspace{0.1\textwidth}
    \begin{subfigure}[b]{0.25\textwidth}
        \includesvg[width=\textwidth, svgpath=./images/Hurst/]{2DDMA_theta04_c}
%         \caption{A random fracture made from two periodic heightmaps.}
%         \caption{$\theta \rightarrow 1$ \\ ($\theta = (n-1)/n$)}
%         \caption{$\theta \rightarrow 1$}
        \caption{$\theta = (n-1)/n$}
        \label{fig:DMA_theta_c}
    \end{subfigure}
        \caption{
        Illustration of what the parameter $\theta$ controls in the detrending moving average method in 2 dimensions. The circles are points where the surface is defined, the red star is the point $(i,j)$, and the black square encompasses the points averaged over to calculate $\tilde f_n(i,j)$ in \cref{eq:carbone_average_rewritten}. The illustration uses $n = 3$.
        \label{fig:DMA_theta}
    }
\end{figure}

We then define the generalized variance $\sigma_\text{DMA}^2$
\begin{align*}
    \sigma_\text{DMA}^2 
    = \frac{1}{(N-n)^2}\sum_{i=n-m}^{N-m} ~ \sum_{j=n-m}^{N-m} 
    \big(
        f(i,j) - \tilde f_n(i,j)
    \big)^2,
\end{align*}
where we see that $f(i,j) - f_n(i,j)$ is the difference between the point $(i,j)$ and the average of a square of points (including the point itself) of size $n \times n$, as explained above (see \cref{fig:DMA_theta}).
% (the position of the square is controlled by the parameter $\theta$, as explained above, and illustrated \cref{fig:DMA_theta}). 
The summation limits $(n-m) \leq i,j \leq N-m$ are set so that the averages $f_n(i,j)$ don't exceed the domain with size $N \times N$.

The generalized variance goes as
\begin{align*}
    \sigma_\text{DMA}^2 \sim \left(2n^2\right)^H,
\end{align*}
which we can use to find the Hurst exponent $H$, by calculating $\sigma_\text{DMA}^2$ for different sizes of the squares, $n$. We estimate $H$ by a linear fit of $\log \sigma_\text{DMA}^2$ against $\log 2n^2$, where $H$ is the slope.

In the paper that generalizes DMA to higher dimensions\cite{carbone2007algorithm} they use different parameters for each spatial dimension $d$, $\bvec\theta = \theta_1, \dots, \theta_d$ and $\bvec{n} = n_1, \dots, n_d$, but for simplicity and to avoid \hl{strange} results, we use $\theta_1 = \theta_2 = \theta$ and $n_1 = n_2 = n$.

% With $\theta = 0$ we have $m = 0$ and average over all points $(\leq k \leq i,l \leq j)$. 

% With $\theta = n/(n-1)$ we have $m = n-1$, and average over all points $(k \geq i,l \geq j)$.

% We define the generalized variance $\sigma_\text{DMA}^2$ as the variance 
% \begin{align*}
%     \sigma_\text{DMA}^2 
%     = \frac{1}{(N-n)^2}\sum_{i=n-m}^{N-m}\sum_{j=n-m}^{N-m} 
%     \big(
%         f(i,j) - \tilde f_n(i,j)
%     \big)^2,
% \end{align*}
% where\footnote{We rewrite \cref{eq:carbone_average} for easier understanding}
% \begin{align}
%     \tilde f_n(i,j) 
%     &= \frac{1}{n^2}\sum_{k=-m}^{n-1-m}\sum_{l=-m}^{n-1-m} f(i-k, j-l) \label{eq:carbone_average}\\
% %     &= \frac{1}{n^2}\sum_{k=i-m}^{i-n+1+m}\sum_{l=j-m}^{j-n+1+m} f(i-k, j-l) \\
%     &= \frac{1}{n^2} \sum_{k=(i+m)-n+1}^{i+m} ~ \sum_{l=(i+m)-n+1}^{i+m} f(k, l).\nonumber %\label{eq:carbone_average_rewritten}
% \end{align}
% \begin{align*}
%     m = \left \lfloor n\theta \right \rfloor
% \end{align*}
% $\theta = 1$ or $\theta = 0$ (directed implementation, for fractals with preferential growth direction) \\
% $\theta = 0.5$ (isotropic implementation, ``uniformity in all orientations'') \\



% \begin{figure}
%     \centering
%     \includesvg[width=0.99\textwidth, svgpath=./images/Hurst/]{2DDMA_theta04}
%     \caption{
%         Illustration of what the parameter $\theta$ controls in the detrending moving average method in 2 dimensions. The circles are points where a surface is defined, the red star marks the point $(i,j)$, and the black square marks the points averaged over to calculate $\tilde f_n(i,j)$ in \cref{eq:carbone_average_rewritten}.
%         \label{fig:DMA_theta}
%     }
% \end{figure}



% \subsubsection{Detrended fluctuation analysis in higher dimensions}
% original DFA\cite{peng1994mosaic}
% HDDMA\cite{gu2006detrended}
% 
% To estimate the Hurst exponent of a fracture we use a generalized version of a method called \emph{detrended fluctuation analysis}\cite{peng1994mosaic}, which was generalized to higher dimensions by Gu and Zhou\cite{gu2006detrended}.
% 
% The two-dimensional DFA:
% 
% We have a self-affine surface stored in the matrix $f(i,j)$, where $f$ \hl{is} the height of the surface in the point $(i,j)$, with $i,j = 1,\dots,N$, and $N^2$ is the number of points where the surface is defined. The surface is divided into $n\times n$ disjoint (non-overlapping) \hl{and neighboring} surfaces \todo{sub-surface?} of the same size $s\times s$, where $n = N/s$. Each of these surfaces is denoted by $f_{u,v}$ such that $f_{u,v}(i,j) = f(i+k, j+l)$ for $i,j = 1, \dots, s$, where $k = (u-1)s$ and $l = (v-1)s$.
% 
% For a surface $f_{u,v}$ the cumulative sum $F_{u,v}(i,j)$ is calculated as follows
% \begin{align*}
%     F_{u,v}(i,j) = \sum_{m=1}^i\sum_{n=1}^j f_{u,v}(m,n),
% \end{align*}
% where $i,j = 1,\dots,s$. Note that F_{u,v}(i,j) itself is a surface.
% 
% The trend of the constructed surface $F_{u,v}$ can be determined by fitting it with a polynomial $\tilde F$



\todo[inline]{implemented in Matlab/Octave}

\subsection{Surface area}
\subsection{Distance to nearest atom}
\begin{itemize}
    \item Fractals
    \item Fractional Brownian Motion
    \item The Hurst Exponent
\end{itemize}

\section{Generating fractures}
\hl{Stuff to define?}
\begin{itemize}
    \item fBm surfaces
    \item Hurst exponent
    \item Gaussian random variable ?
    \item non-stationary
    \item self-similar
    \item isotropic
    \item lacunarity
\end{itemize}

\subsection{Generating surfaces}
% When generating random surfaces we want to be able to control the properties like the Hurst exponent (\hl{etc.?}) of the surface.

To generate our random surfaces we use an iterative midpoint displacement method usually called successive random additions \hl{(SRA)}. The method is based on a method proposed by Fourner in 1982\cite{fournier1982computer}, but with some modifications suggested by Voss\cite{voss1985random, voss1988fractals}. The method has further been discussed by Saupe\cite{saupe1988algorithms}, amongst others. We choose this method mainly because it's possible to generate periodic surfaces with it, because it generates very good approximations to fBm surfaces\cite{zhou2005comparison}, and because the Hurst exponent of the generated surfaces is easy to control. The method is also easy to understand, easy to implement, and generates surfaces with high resolution very fast. The method is widely used in scientific applications\hl{cite??} because of these properties, and is also used for generating surfaces in computer graphics, since the surfaces look very realistic \hl{with only some minor artefacts?? (high, narrow peaks)}.

\subsubsection{Midpoint displacement method in 1 dimension}
The method we use to generate random surfaces is very similar to the standard midpoint displacement method, which in 1 dimension goes as follows. See \cref{fig:midpoint01} for a visual presentation.
\begin{enumerate}
    \item Give the values at the endpoints of the interval, $y_0$ and $y_n$, random values from a Gaussian random variable with mean $\mu = 0$ and variance $\sigma_0^2$. This initial standard deviation $\sigma_0$ can be chosen freely.
    \item Generate the value in the center of the interval, $y_{n/2}$, by averaging over the two endpoints and adding a Gaussian random number with mean $\mu = 0$ and a \emph{reduced} variance
    \begin{align}
         \sigma_1^2 = \left(1/2\right)^{2H}\sigma_0^2, \label{eq:midpoint_sigma_first}
    \end{align}
    where $H$ is the wanted Hurst exponent.
    \item Continue generating the values in the center of each sub-interval until you reach the desired number of points, while reducing the variance of the random number by a factor $\frac{1}{2}$ each iteration\todo{Why 1/2? (needed to create good fBm, see \cite{voss1985random})}. For iteration $i$ we have
    \begin{align}
        \sigma_i^2 = \left(1/2\right)^{i2H}\sigma_0^2. \label{eq:midpoint_sigma_general}
    \end{align}
\end{enumerate}

\begin{figure}
    \centering
    \includesvg[width=0.5\textwidth, svgpath=./images/diamond_square/]{random_midpoint_displacement_regular02}
    \caption{
        \hl{Illustration of the midpoint displacement method in 1 dimension.}
        \label{fig:midpoint01}
    }
\end{figure}

This method generates a \hl{1-dimensional line}, with a Hurst exponent \hl{close} to the input $H$\todo{how close?}. But since we only add random numbers to the new values, the result is non-stationary for $H \neq 0.5$\cite{voss1985random}\hl{, and it is neither self-similar or isotropic, as noted by Mandelbrot}\cite{mandelbrot1982comment}. To mitigate this we implement the addition suggested by Voss\cite{voss1985random}, which consists of adding a random number to \emph{all} points in each iteration, both the new and old. Voss called this modified method \emph{successive random additions}.

\subsubsection{Successive random additions \hl{(on an infinite grid)} in 2 dimensions}
As mentioned before, the method called \emph{successive random additions} is a modification of the regular midpoint displacement method first described by Richard F. Voss\cite{voss1985random}, where we add random numbers to \emph{all} points in each iteration, compared to just the \emph{new} points in the regular midpoint displacement method. This modification means that we can replace the factor $(1/2)$ in \cref{eq:midpoint_sigma_first,eq:midpoint_sigma_general} with a general factor $r$\todo{why? (something about distance between points)}, and we get
\begin{align*}
    \sigma_i^2 = r^{2H}\sigma^2_{i-1}.
\end{align*}
\hl{$r$ controls the lacunarity/roughness, $H$ independent of $r$}

Voss has geneneralized the the method of successive random additions to higher dimensions\cite{voss1985random}, and this generalized form is the algorithm we use when generating fractures. We generate surfaces in the form of heightmaps, meaning a 2-dimensional grid of points ({$x,y$}), with a value for the height in each point \hl{($z(x,y) = z_{x,y}$)} which is generated by the algorithm.

The central part of the algorithm consists of two steps often called the \emph{diamond-step} and the \emph{square-step}. We start with a simple case of an infinite grid of evenly spaced points, all with known $z$-values. The two steps are as follows:
\begin{description}
    \item[The \emph{square-step}:] The grid can be divided into small squares consisting of four points in each square, as in the leftmost square in \cref{fig:simple_square_step}. We generate the $z$-value in the center of each of these squares by averaging the $z$-values of the four corners of each square, as indicated by the red dots and arrows in \cref{fig:simple_square_step}. Then add a random Gaussian number with mean $\mu = 0$ and variance $\sigma_i^2 = \sigma_{i-1}^2r^{2H}$ to all new and old points, where $\sigma_{i-1}^2$ is the variance used in the last step of the algorithm.
    \label{enum:test}
    
    \item[The \emph{diamond-step}:] After the square-step the grid can be divided into smaller squares that are tilded by 45 degrees, as in the leftmost square in figure \cref{fig:simple_diamond_step}. We generate the $z$-values in the center of each square by averaging the $z$-values of the four corners of each square, as indicated by the red dots and arrows in \cref{fig:simple_diamond_step}. We then add a random Gaussian number with mean $\mu = 0$ and variance $\sigma_{i+1}^2 = \sigma_i^2r^{2H}$, to all new and old points. 
\end{description}
See \cref{fig:diamond_square_applied} for an illustration of the algorithm applied once on a larger grid. 

\begin{figure}
\centering

\setlength{\myfigwidth}{0.5\textwidth}
\setlength{\mycaptionwidth}{0.3\textwidth}

\begin{minipage}[c]{\myfigwidth}
    \includesvg[width=\textwidth, svgpath = images/diamond_square/]{simple_square_step_solarized08}
\end{minipage}
\begin{minipage}[c]{\mycaptionwidth}
    \subcaption{Square-step}
    \label{fig:simple_square_step}
\end{minipage}

\begin{minipage}[c]{\myfigwidth}
    \includesvg[width=\textwidth, svgpath = images/diamond_square/]{simple_diamond_step_solarized05}
\end{minipage}
\begin{minipage}[c]{\mycaptionwidth}
    \subcaption{Diamond-step}
    \label{fig:simple_diamond_step}
\end{minipage}

\caption{Illustration of the two steps used in the diamond square algorithm for generating random surfaces. The grey points are old points, the black points are new points, and the red points are the points used in the calcuation of the averages when generating the new points.}
\label{fig:diamond_square_steps}
\end{figure}

We see that by first applying the square-step and then applying the diamond-step, we add one point in between each point in each direction, almost doubling the resolution of the grid. In general we go from $n$ to $n + (n-1)$ points in each direction. By applying the algorithm several times we get \todo{replace $n$ with $N$ and $i$ with $n$?}
\begin{align}
    n_1 &= n_0 + (n_0-1) = 2n - 1 \nonumber\\
    n_2 &= 2n_1 - 1 = 4n_0 - 3 \nonumber\\
    n_3 &= 2n_2 - 1 = 9n_0 - 7 \nonumber\\
    &\vdotswithin{=} \nonumber\\
%     &\shortvdotswithin{=}
    n_i &= 2^i(n_0-1) + 1, \label{eq:diamond_step_resolution}
\end{align}
where $i$ is the number of times we have applied the algorithm. This means that using the diamond-square algorithm we can go from any resolution $n_0$ to all resolutions satisfying $n_i = 2^i(n_0 - 1) + 1$.

\begin{figure}
    \centering
    \includesvg[width=0.7\textwidth, svgpath = images/diamond_square/]{increase_resolution_solarized_starssquares03}
    \caption{
        The diamon-square algorithm applied once on a grid of $3\times 3$ points, increasing the number of points from 9 to 25. The orange square points are generated by the square-step (see \cref{fig:simple_square_step}), and the blue star-shaped points by the diamond-step (see \cref{fig:simple_diamond_step}).
    }
    \label{fig:diamond_square_applied}
\end{figure}

\subsubsection{Successive random additions on a finite grid \hl{in 2 dimensions}}
Since we are using computers to generate our surfaces, which have limited memory, we can't use infinite grids. This means we get some special cases that needs to be taken care of when generating points near the edges of the grid.\todo{transition to below}

For the square step we generate one new point in the center each square formed by the grid from the previous iteration, and in general we generate the values in the points
\begin{align*}
    &\left(x_{i+1/2}, y_{j+1/2}\right) &0\leq i,j < n,
\end{align*}
where $(x_i,x_j)$ are the points in the grid after the last iteration. In general the average we calculate for the new points can be written as
\begin{align*}
    (x_{i+1/2}, y_{j+1/2}) 
    = \frac{1}{4}\big(
        (x_i, y_j) + (x_{i+1}, y_j) + (x_i, y_{j+1}) + (x_{i+1}, y_{j+1})
    \big).
\end{align*}
We see that the square-step only uses points inside the grid, which means that we don't have to modify it when going to a finite grid.

For the diamond-step we generate the values in the points

\begin{align*}
    &(x_{i+1/2}, y_j) &\text{for } 0\leq i<n \text{ and } 0\leq j \leq n& \\
    &(x_i, y_{j+1/2}) &\text{for } 0\leq i\leq n \text{ and } 0\leq j < n&.
\end{align*}
In general the averages we calculate for the new points can be written as
\begin{align*}
    (x_{i+1/2}, y_j) 
    &= 
    \frac{1}{4}\big(
        (x_i, y_j) + (x_{i+1}, y_j) + (x_{i+1/2}, y_{j-1/2}) + (x_{i+1/2}, y_{j+1/2})
    \big)\\
    (x_i, y_{j+1/2}) 
    &= 
    \frac{1}{4}\big(
        (x_i, y_j) + (x_i, y_{j+1}) + (x_{i-1/2}, y_{j+1/2}) + (x_{i+1/2}, y_{j+1/2})
    \big).
\end{align*}
We now see that when generating points near the edges, when generating the points $(x_{i+1/2}, y_j)$ for $j \in \{0, n\}$ and $(x_i, y_{j+1/2})$ for $i = \{0, n\}$, we need to average over points that lie outside the grid. There are two possible solutions, depending on the surface we are generating. If generating a periodic surface, the solution is to wrap around the edges using periodic boundary conditions, and find the point we need on the opposite side of the grid. For example (using $i = j = 0$)
\begin{align*}
    (x_{1/2}, y_{-1/2}) = (x_{1/2}, y_{n-1/2}).
\end{align*}
If generating a non-periodic grid we simply ignore the points that lie outside the grid when calculating the averages, and just use the \hl{three/3} other points.

\subsubsection{Implementing successive random additions \hl{on a finite grid in 2 dimensions}}
In our implementation we generate a surface on a finite grid of size $N\times N$. As shown in \cref{eq:diamond_step_resolution} the algorithm can go from any resolution $n_0$ to $n_p = 2^p(n_0-1) + 1$ by applying the algorithm $p$ times. This is useful to know, since on a computer we prefer allocating a matrix to store the surface before starting the computations.

To ensure that the generated surfaces are periodic (when generating a periodic surface) we let the right and bottom edge be equivalent to the left and top edge, respectively (this means that the four corners are equivalent). This effectively means that the resolution of the periodic surfaces we generate is $2^n$ instead of $2^n+1$


This leaves us with the following algorithm for generating a surface which approximates a 2-dimensional fractional Brownian motion with Hurst exponent $H$
\begin{enumerate}
    \item Start with a grid of size $n \times n$, where $n = 2^p + 1$, and $p$ is a positive integer. Generate the values in the corners by drawing a random 
    
    \item Generate the $z$-value in the center of each square of already defined points by using the square-step, as in \cref{fig:square_step}. Add a random Gaussian value with mean $\mu = 0$ and variance $\sigma_0^2$ to all new and old points. The initial standard deviation $\sigma_0$ can be chosen freely.
    
    \item Generate the $z$-value in the center of each 
    
    \item Generate the $z$-value in the center of the grid using the square step by averaging over the four corners, as shown in \cref{fig:initial_square_step}. Add a random Gaussian number with mean $\mu = 0$ and variance $\sigma_1^2 = \sigma_0^2r^{2H}$\todo{define r} to the new point, and to the four corners (add the same number to all four corners to keep the system periodic).
    
    \item Generate the values in the middle of the top and left edge of the grid using the diamond step, as shown in \cref{fig:diamond_step}. Add a random Gaussian number with mean $\mu = 0$ and variance $\sigma_2^2 = \sigma_1^2r^{2H}$ to all new and old points. Set the point in the middle of the right and bottom edges equal to 
    
    When calculating the averages in the diamond-step  Since the surface is periodic, we can wrap around the edges to reach the points beyond the edges of our grid (the points outside the grid in \cref{fig:diamond_step}). Set values in the middle of the right and bottom edge equal to the corresponding values in the middle of the left and top edge, to keep the surface periodic\footnote{\hl{We could have done this in a slightly different way, by making the grid one unit smaller, and starting with only one point in one of the corners, but by doing it the way we have we can keep the square step the same as before.}}.
    
%     \item We now need to generate the $z$-values in the middle of the four edges of the grid, using the diamond step. But since we have a finite and periodic grid, we have to wrap around the edges when taking the average over the four neighbours. We also see that the top and bottom edge, and the left and right edge should be equal after generating the new points\footnote{\hl{We could have done this in a slightly different way, by making the grid one unit smaller, and starting with only one point in one of the corners, but doing it the way we have we can keep the square step the same as before.}}, to keep the grid periodic. This can for example be done by generating the point in the middle of the left edge and the point in the middle of the top edge by using the diamond step and wrapping around the edges, and then setting the corresponding points on the right and bottom edge equal to the generated points.
    
%     This can for example be done by only generating the points on the top and left edge, and then setting the points on the right edge equal to the left edge, and the points on the .

    \item Continue generating new points and increasing the resolution of the \hl{surface/grid} until you reach the desired number of \hl{points/resolution}. We see in \cref{fig:square_step} that the square step doesn't need any changes, since we don't generate any points at the edges of the grid, and we never have any neighbors that are beyond the edges of the grid. For the diamond step we need to make sure we wrap around the edges to find neighbors when calculating points that are close to the edges of the grid, and that we update the left and bottom edges as needed. 
    
    For step $i$ the variance of the random Gaussian number is
    \begin{align*}
        \sigma_i^2 = \sigma_0^2(r^i)^{2H}.
    \end{align*}
\end{enumerate}

See \cref{fig:diamond_square_surface} for a surface generated by the algorithm.

\begin{figure}
    \centering
    \includesvg[width=0.7\textwidth, svgpath=./images/diamond_square/surface_example/]{surface_labels}
    \caption{
        Caption.
        \label{fig:diamond_square_surface}
    }
\end{figure}

On a computer we would like to allocate a matrix for storing each point in the final surface before using the algorithm, which means we have to know the size beforehand.

In our implementation of the algorithm we start from a grid with the $z$-value in each corner defined (a resolution of $2\times 2$), which means our final resolution is $n_i = 2^i + 1$ after $i$ iterations, and that we should allocate a matrix of size $(2^i + 1) \times (2^i + 1)$ in the initialization of the program.

\orangebox{
{\bf Notes:}
\begin{itemize}
    \item Implementation (in Matlab/C++)?
    \item Mention that DS can be used to increase resolution of any surface
    \item Can increase resolution of generated surface, if we know the seed
\end{itemize}

{\bf Stuff to define:}
\begin{itemize}
    \item Periodic/non-periodic
    \item Lacunarity
\end{itemize}
}

% \begin{figure}
%     \centering
%     \def\svgwidth{\textwidth}
%     \input{images/diamondSquare02.eps_tex}
% \end{figure}

% \begin{figure}
%     \centering
%     \def\svgwidth{\textwidth}
%     \input{images/diamondSquare03.pdf_tex}
% \end{figure}

% \subsection{Successive Random Addition}
% To generate a random heightmap with a known Hurst exponent we used the successive random addition (SRA) algorithm introduced by Voss\cite{voss1985random}. It is a variation of a simpler algorithm called random midpoint displacement (RMD), a subdivision method described by, amongst others, Fournier, Fussell, and Carpenter\cite{fournier1982computer, carpenter1980computer}. To illustrate how the algorithms work, we will start with a simple 1-dimensional example of RMD.
% 
% We start with two points $Y(0)$ and $Y(1)$ at the edges of our interval. We find a point $Y(\frac{1}{2})$ in the center of the interval by interpolating the two initial points, and adding a Gaussian random number with zero mean and variance $\sigma^2$
% 
% \subsection{Midpoint Displacement Method}
% The most basic method we used is a very basic but widely used method, which has many variations and names. The most common names are ``the diamond-square algorithm''\hl{cite}, ``the midpoint displacement method''\hl{cite}, ``plasma fractal'' and ``cloud fractal''.
% 

\subsection{Generating fractures from surfaces}
To generate a realistic fracture we use the method of successive random additions, as described previously, to generate random heightmaps with a known Hurst exponent. If we generate two of these surfaces we can make a fracture by putting one surface above the other, and letting either the space between or outside the heightmaps be the void. Since we are using periodic systems the two different approaches are equivalent, but we chose to let the space between the heightmaps be the void, for easier visualization.

In practice we make a fracture using the following procedure
\begin{itemize}
    \item Generate two heightmaps.
    \item Rescale the $x$- and $y$-positions of all points in the heightmaps, so they span the size of the atomic system.
    \item Rescale the $z$-values of the heightmaps so all points are inside the system.
    \item Remove all atoms between the upper and lower heightmap.
\end{itemize}

Removing all atoms between the two heightmaps isn't a trivial task. We do this by utilizing the fact that the points in each heighmap lie on a regular grid in the $x$-$y$-plane, to divide the volume into tetrahedra. If the two heightmaps are not intersecting, we see that we can divide the volume between them into convex hexahedra, one for each set of points
($x_{i}, y_{i}$), ($x_{i}, y_{i+1}$), ($x_{i+1}, y_{i}$), and ($x_{i+1}, y_{i+1}$) 
% $(x_i, y_i)$  $(x_i, y_{i+1})$ $(x_{i+1}, y_i)$ $(x_{i+1}, y_{i+1})$
in the $x$-$y$-grid. Each of these hexahedra can then be divided into five tetrahedra, as illustrated in \cref{fig:hex_to_tetra}.

% \begin{figure}
%     \centering
%     \includegraphics[width=0.4\textwidth]{images/fracture/hexahedron_to_tetrahedra.png}
%     \caption{
%         Illustration of how to divide a hexahedron into five tetraheda.
%         \label{fig:hex_to_tetra}
%     }
% \end{figure}
% 
% \begin{figure}
%     \centering
%     \includegraphics[width=0.6\textwidth]{images/fracture/fracture.png}
%     \caption{
%         A model of a fracture.
%         \label{fig:fracture_model}
%     }
% \end{figure}

\begin{figure}
    \centering
    \begin{subfigure}[b]{0.35\textwidth}
        \includegraphics[width=\textwidth]{images/fracture/hexahedron_to_tetrahedra01_cycles_n200.png}
        \caption{Illustration of how to divide a convex hexahedron into five tetraheda.}
        \label{fig:hex_to_tetra}
    \end{subfigure}
    \hspace{5mm}
    \begin{subfigure}[b]{0.55\textwidth}
        \includegraphics[width=\textwidth]{images/fracture/fracture05_n200.png}
%         \includegraphics[width=\textwidth]{images/fracture/large_fracture04_300dpi_w20cm}
        \caption{A random fracture made from two periodic heightmaps.}
        \label{fig:fracture_model}
    \end{subfigure}
\end{figure}

\subsubsection{Finding a point inside a tetrahedron}
% To calculate if a point is inside a tetrahedron we utilize the \emph{oriented} volume of a tetrahedron. The oriented volume of a tetrahedron with vertices $\bvec a$, $\bvec b$, $\bvec c$ and $\bvec d$ can be calculated as
% \begin{align*}
%     V = \frac{1}{6}(\bvec a - \bvec d)\big[(\bvec b - \bvec d)\times(\bvec c - \bvec d)\big].
% \end{align*}
% The \emph{ordered} volume simply means that the order of the vertices will determine the sign of the volume. The sign of the volume will be determined by on which side of the plane between $\bvec b$, $\bvec c$ and $\bvec d$ the point $\bvec a$ lies. The cross product $(\bvec b - \bvec d)\times(\bvec c - \bvec d)$ gives a normal vector to the plane, and the dot product projects $(\bvec a - \bvec d)$ onto this normal. The sign of the dot product is positive if $\bvec a$ is located the side of the plane which the normal points towards, and negative else.

% We then compare the sign of the volume of the tetrahedra to the signs of the volumes of four tetrahedra constructed by replacing one of the vertices of the tetrahedra with the point we want to find out if is inside the tetrahedra.



% A tetrahedron consists of four points 
% % $\bvec a$, $\bvec b$, $\bvec c$, and $\bvec d$, 
% % $\bvec r_i$ for $i\in\{1,2,3,4\}$,
% % $x$, $b$, $c$, and $d$, 
% $x_i$ for $i\in\{1,2,3,4\}$,
% and four faces spanned out by the four possible combinations of the four points. For a face spanned by the vectors $\bvec r_i = x_i - x_j$ and $\bvec r_j = x_k - x_j$, where, we can see if a point $P$ is on the same side of the face as the point $\bvec x_{l\neq i,j,k}$ not used to construct the face by doing some geometry. We calculate the normal vector to the face by the cross product $\bvec n = \bvec r_i\times\bvec r_j$. This gives us a normal vector $\bvec n$ to the surface. We then find the sign of dot products $\bvec n (P - x_j)$ and $\bvec n(x_l - x_j)$



A tetrahedron consists of four points $\bvec a$, $\bvec b$, $\bvec c$, and $\bvec d$ and four faces, spanned by the four possible combinations of the four points. For a face spanned by the points $\bvec a$, $\bvec b$, and $\bvec c$ we can find if a point $\bvec P$ is on the same side of the face as the point $\bvec d$ (the point not used to construct the face) by doing some geometry. We calculate the cross product 
\begin{align*}
    \bvec n = (\bvec a-\bvec c)(\bvec b-\bvec c),
\end{align*}
which gives us the normal vector to the surface $\bvec n$. We then find the sign of dot products 
\begin{align*}
    &\bvec n\cdot(\bvec P - \bvec c), \\
    &\bvec n\cdot(\bvec d - \bvec c).
\end{align*}
If the sign of these dot products is the same, we know that the point $\bvec P$ is on the same side of the face as the point $\bvec d$. We now see that if we do this for all four faces of the tetrahedra, we know that the point $\bvec P$ is inside the tetrahedra if the signs of all pairs of dot products are equal.



% Calculating wether a point is inside a tetrahedron can be reduced to comparing the sign of five different matrix determinants. If we have a point $P = (x,y,z)$ and the four vertices of the tetrahedron are $(x_i, y_i, z_i)$ for $i\in \{1,2,3,4\}$, we can find if the point is inside the tetrahedron by checking if the the following five matrix determinants have the same sign
% \begin{align*}
%     &\begin{vmatrix}
%         x_1 & y_1 & z_1 & 1 \\
%         x_2 & y_2 & z_2 & 1 \\
%         x_3 & y_3 & z_3 & 1 \\
%         x_4 & y_4 & z_4 & 1
%     \end{vmatrix},&
%     &\begin{vmatrix}
%         x & y & z & 1 \\
%         x_2 & y_2 & z_2 & 1 \\
%         x_3 & y_3 & z_3 & 1 \\
%         x_4 & y_4 & z_4 & 1
%     \end{vmatrix},&
%     &\begin{vmatrix}
%         x_1 & y_1 & z_1 & 1 \\
%         x & y & z & 1 \\
%         x_3 & y_3 & z_3 & 1 \\
%         x_4 & y_4 & z_4 & 1
%     \end{vmatrix},&
%     \\
% %     \vspace{5mm}
%     \\
%     &\begin{vmatrix}
%         x_1 & y_1 & z_1 & 1 \\
%         x_2 & y_2 & z_2 & 1 \\
%         x & y & z & 1 \\
%         x_4 & y_4 & z_4 & 1
%     \end{vmatrix},&
%     &\begin{vmatrix}
%         x_1 & y_1 & z_1 & 1 \\
%         x_2 & y_2 & z_2 & 1 \\
%         x_3 & y_3 & z_3 & 1 \\
%         x & y & z & 1
%     \end{vmatrix}.&
% \end{align*}
