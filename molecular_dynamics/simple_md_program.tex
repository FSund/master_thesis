\chapter{A simple molecular dynamics model\label{chap:simple_md_program}}
\todoa{Write MD intro}
Intro

From old stat mec chapter:
In molecular dynamics we study systems of many interacting atoms and molecules by assuming that they behave classically, and solve Newton's equations of motion using an appropriate integration scheme to evolve the system in time. By assuming that the atoms behave classically we mean that we model the atoms as point particles, and characterize them using their position, $\bvec r$, velocity, $\bvec v$ and the force acting on them, $\bvec f$. The interactions between the atoms, that stem from the quantum mechanical \hl{something}, are described using potentials. It is into these potentials we bake the physical insight of the systems we want to simulate, which we often do by finding potentials using studies and simulations of the underlying quantum mechanical nature of the interactions between the atoms in the system.

\section{The main program}
% Deducing how a molecular dynamics program does its simulations isn't always easy from looking at source code, but most programs will follow a flow similar to the following:
%
Using a molecular dynamic simulations we can start from any initial state $S_0$ and evolve this state in time. We can stop the simulations at any time, and continue the simulations from any saved state. This is a powerful tool that can be used to study different systems with the same initial conditions. 

Most molecular dynamics programs will follow a flow similar to the following:
%
\begin{itemize}[midsep]
    \renewcommand{\labelitemii}{$\bullet$} % Set list depth 2 bullet thing equal to first
    \item Initialize the system by setting up the initial positions and velocities for all atoms. This is usually in one of two ways
    \begin{itemize}[midsep]
        \item Loading a saved state from a previous simulation
        \item Generated positions and velocities randomly, or following some rules to control the structure and/or distribution of velocities. When generating random velocities we usually remove any net velocity by subtracting the mean velocity in each spatial direction from the velocities of all atoms.
    \end{itemize}
    \item For each timestep
    \begin{itemize}[midsep]
        \item Calculate the forces between the atoms.
        \item Integrate Newton's equations of motion using an appropriate integration scheme.
        \item Sample the values of the quantities we want to study, and add to the averages.
    \end{itemize}
    \item After all timesteps have been finished we print out the measured quantities, and we could also save the state of the system so we can continue from this state later.
\end{itemize}
%
An example of a program that implements the above procedure can be seen in \cref{list:simple_md_program}.
%
\begin{listing}[!htb]%
\begin{cppcode*}{gobble=4}
    System system = initializeSystem(parameters);
    double time = 0.0;
    double dt = 0.01;
    for (double time = 0; time < tMax; time += dt) {
        calculateForces(system);
        integrateEquationsOfMotion(system, dt);
        sample(system);
    }
\end{cppcode*}
\caption{%
    An example of a typical implementation of a molecular dynamics program using object-oriented programming. See \cref{list:calculate_forces,list:regular_verlet,list:sampling} for examples of implementations of the functions \mono{calculateForces}, \mono{integrateEquationsOfMotion}, and \mono{sample}.%
    \label{list:simple_md_program}%
}%
\end{listing}%

When starting a new simulation we usually initialize the positions of the atoms by putting them on a regular grid like a face-centered cubic (fcc), a body-centered cubic (bcc), or a simple cubic grid. The purpose of this is to not have any atoms too close to each other, since we usually have a strong repulsive force when the atoms get close together,  which would give very big forces. We also want to start with the atoms in a state from which we are able to quickly get to the state we want to study. If we for example want to study a liquid argon system, it is wise to start in an unstable crystal state, by for example using a low density or high temperature, so that the system would melt spontaneously when we start the simulation.

\section{Calculation of forces\label{sec:program:lj}}
The forces are calculated from the derivatives of interatomic potentials, that usually only depend on the positions of the atoms. The potentials are generally of the form
\begin{align*}
    U(\rvec) = \sum_{i<j} U_{ij}(r_{ij}) + \sum_{i<j<k} U_{ijk}(\rvec_i, \rvec_i, \rvec_k) + \dots,
\end{align*}
where $\rvec_i$ is the position of atom $i$, $r_{ij}$ is the distance between atom $i$ and $j$, $U_{ij}$ is a two-particle potential depending only on the distance between two atoms, and $U_{ijk}$ is a three-particle potential that usually also depends on the angle between three atoms. Higher-order contributions to the forces are also sometimes used, but these are very demanding to calculate.

The potentials are often developed from quantum mechanical calculations, and when doing this one has to weigh the benefits of having a complex potential that models the interactions accurately, against having a less complex potential that will be easier to implement, and faster to evaluate. The limiting factor in any molecular dynamics calculation is the cost of doing simulations on high-performance computing clusters (like Abel at UiO), but luckily it seems like the progress in computer development still seems to \hl{almost} follow Moore's Law\cite{mack2011moore}, which states that the number of transistors on integrated circuits double approximately every two years\cite{moore1965cramming}, effectively every two years halving the price of doing \hl{the same} computation.

In this example we will be using a potential first seen as early as 1924\cite{jones1924potential} called the Lennard-Jones potential, \hl{after its creator(s)}, who used to to study the \hl{noble gas} Argon \hl{(among other stuff?)}. The potential is a two-particle potential with the following form
% To model a simple mono-atomic system we use the well-known Lennard-Jones potential\cite{jones1924potential}, which when applied on the noble gas \hl{(inert)} Argon gives results that are in good agreement with experimental results. The potential is usually written as follows
\begin{align}
%     U(r) = 4\varepsilon \Big[
%     \underbrace{
%         \left(\frac{\sigma}{r}\right)^{12}
%     }_{\text{attraction}}
%      - 
%     \underbrace{
%         \left(\frac{\sigma}{r}\right)^6
%     }_{\text{repulsion}}
%     \Big],
    U(r_{ij}) = 4\varepsilon\left[ \left(\frac{\sigma}{r}\right)^{12} - \left(\frac{\sigma}{r}\right)^{6} \right]
    = \varepsilon\left[ \left(\frac{r_m}{r}\right)^{12} - 2\left(\frac{r_m}{r}\right)^{6} \right],
    \label{eq:lennard-jones_potential}
\end{align}
where $\sigma$ is the distance between where the potential is zero \hl{(the equilibrium distance between the atoms)}, $\varepsilon$ is related to the strength of the potential (the minimum value of the potential), and $r_m = 2^{1/6} \sigma$ is the distance where the potential is at its minimum. The $r^{-12}$-term is a repulsive term that describes \hl{Pauli repulsion/steric repulsion/overlap of electron orbitals} and the $r^{6}$-term is an attractive term that describes \hl{long range/van der Waals/dipole-dipole/dispersion} interactions. \todobo{something about physical justification, use 6 for repulsive because $r^{12} = (r^6)^2$}

Even though the potential is simple, it describes many properties noble gases like Argon well, and its simplicity also means that the computational cost of calculating the forces between atoms is low. For these reasons it has been used in a lot of studies\todoco{to study what? Examples}. See \cref{fig:lennard-jones_potential} for a plot of the potential using the parameters usually used for simulating Argon\cite{frenkel2001understanding}, $\sigma = 3.405$~\AA\ and $\varepsilon = 0.010318$~eV.
%
\tododone{find section for Argon parameters ref in \cref{fig:lennard-jones_potential}}%
%
\begin{figure}[htpb]%
    \centering%
    \includesvg[width=0.7\textwidth, svgpath=./images/lennard-jones/]{lennard-jones_manualalign01}%
%     \includesvg[width=0.7\textwidth, svgpath=./images/lennard-jones/]{lennard-jones}%
    \caption{%
        Plot of the Lennard-Jones potential, as stated in \cref{eq:lennard-jones_potential}. Using the parameters usually used for simulating Argon, $\sigma = 3.405$~\AA\ and $\varepsilon = 0.010318$~eV\cite{frenkel2001understanding}.%
        \label{fig:lennard-jones_potential}%
    }%
\end{figure}%

\subsection{Newton's third law}
When calculating two-particle forces like the Lennard-Jones potential there is a simple optimization that lets us halve the number of computations, by utilizing Newton's third law. We see that when evaluating $U(r_{ij})$, the force will have the same magnitude if we switch particle $i$ and $j$. This means that when we have calculated the force $\vec F_{ij}$, from particle $j$ on particle $i$, we know that the force on atom $j$ from particle $i$ will have the same magnitude, and we can simply add the opposite force to atom $j$, $\vec F_{ji} = -\vec F_{ij}$. This way we only have to calculate the forces between particle $i$ and particles $j>i$ in the main force loop.

See \cref{list:calculate_forces,list:calculate_force_between_atoms} for an example of how to implement force calculation using the Lennard-Jones potential, using this optimization.
%
\begin{listing}[!htb]%
% \begin{cppcode*}{gobble=4}
%     void calculateForces(System &system)
%     {
%         for (Atom *atom1 : system.atoms())
%         {
%             for (Atom *atom2 : system.atoms())
%             {
%                 
%             }
%         }
%     }
% \end{cppcode*}
%         for (vector<Atom*>::iterator atom1 = atoms.begin(); atom1 != atoms.end(); ++atom1)
\begin{cppcode*}{gobble=4}
    void calculateForces(System &system) {
        const vector<Atom*> &atoms = system.atoms();
        for (auto atom1 = atoms.begin(); atom1 != atoms.end(); ++atom1) {
        
            // Use Newton's third law to skip half the force calculations
            for (auto atom2 = atom1.next(); atom2 != atoms.end(); ++atom2) {
                vec3 force = calculateTwoParticleForce(*atom1, *atom2);
                
                (*atom1)->force() += force;
                (*atom2)->force() -= force; // Newton's third law
            }
        }
    }
\end{cppcode*}
\caption{%
%     An example of how to implement the velocity Verlet integration scheme using \cpp-like object-oriented programming.%
    Implementation of \mono{calculateForces} from \cref{list:simple_md_program}. See \cref{list:calculate_force_between_atoms} for example implementation of \mono{calculateTwoParticleForce}.%
    \label{list:calculate_forces}%
}%
\end{listing}%
%
\begin{listing}[!htb]%
\begin{cppcode*}{gobble=4}
    vec3 calculateTwoParticleForce(Atom *atom1, Atom *atom2) {
        vec3 drVec = atom1->position() - atom2->position();
        
        double dr2 = drVec.lengthSquared();
        double dr6 = dr2*dr2*dr2;

        double LJforce = 24.0*(2.0 - dr6)/(dr6*dr6*dr2);
        vec3 force = drVec*LJforce;
        
        return force;
    }
\end{cppcode*}
\caption{%
%     An example of how to implement the velocity Verlet integration scheme using \cpp-like object-oriented programming.%
    Implementation of \mono{calculateTwoParticleForce} from \cref{list:calculate_forces}, using the Lennard-Jones potential.%
    \label{list:calculate_force_between_atoms}%
}%
\end{listing}%

\todobo{Remove \cref{list:calculate_force_between_atoms} ?}
If we are using higher-order potentials we can use the same optimization for the two-particle terms of the potential, but it's a bit more complicated for the terms depending on the positions of three or more particles, but there are still similar optimizations that can be done if we are smart.

\input{molecular_dynamics/integration_scheme.tex}


\section{Boundary conditions}
\tododo{Cite Born and Von Karman 1912? (See Comp. Sim. of Liquids p. 24 (39)}
In theory we now have a working molecular dynamics program by combining \cref{list:simple_md_program,list:calculate_forces,list:calculate_force_between_atoms,list:regular_verlet}. But if we start our simulations we will quicly see that the particles will start spreading out into space, since we haven't implemented any kind of boundary conditions. The particles that are on the surface of our initial system will feel very different forces than the ones in the center, and will most likely not behave as intended. To remedy this we use periodic boundary conditions. This means that we repeat the simulation box at the boundaries of the system, so that the atoms near the boundaries feel forces from atoms on the opposite side of the system, and in a uniform system all atoms will have a bulk-like environment. 

Atom $n$ has what we call an \emph{image} in all other neighbor boxes, with position
\begin{align}
    \rvec_n^{ijk} = \rvec_l + (iL_x, jL_y, kL_z),
    \label{eq:pbc_positions}
\end{align}
where $(L_x, L_y, L_z)$ is the dimensions of the simulation box, and $(i, j, k)$ is the index of the neighbor box. We usually choose box $(0,0,0)$ as our ``origin'' box, with the corner of the box in the point $(0,0,0)$. In reality we still have the same number of atoms, but the atoms on near the boundaries of the simulation box will now feel forces from the atoms on the opposite side of the box.

The first thing we have to do to implement periodic boundary conditions is to check if any atoms have moved outside the boundaries of the system after each timestep, after updating the positions of the atoms. If they have moved outside the boundaries of the system we see from \cref{eq:pbc_positions} that we can translate them back into the system by adding or subtracting an appropriate number of system sizes $L_i$ from the coordinates that are outside the box. If the boundaries of our system is $x_i \in [0, L_i]$ we can translate the atomic positions outside the boundaries to the correct positions inside the boundaries by using the modulo operator. By finding the remainder of dividing the coordinates of an atom with the system size, we get back the position of the atom translated back inside the boundaries, as follows (for the $x$-coordinate)
\begin{align*}
    x_i^{000} = x_i^{ijk} \bmod L_x.
\end{align*}
When implementing this we have to be wary of what happens if we have negative coordinates, as the modulo of a negative number has different implementations in different programming languages. To avoid this problem we usually just add one system size to each coordinate before using the modulo operator, to ensure that the coordinates are positive. In doing this we assume that no atoms have moved more than one system size in negative direction, but this shouldn't happen if we use an appropriate timestep and our integrator is working like it should\footnote{If we want to ensure that atoms that have moved further than one system size in any direction gets translated back into the box we can add $n$ system sizes to each coordinate before performing the modulo operation.}. 

An example of how to ensure that all atomic positions are inside the boundaries of the system using the modulo operator can be seen in \cref{list:pbc}.
\begin{listing}[!htb]%
% \begin{cppcode*}{gobble=4}
%     void checkBoundaryConditions(System &system, const vec3 &systemSize)
%     {
%         for (Atom *atom : system.atoms())
%         {
%             for (int dim = 0; dim < 3; dim++)
%             {
%                 if (atom->position()[dim] < 0.0) 
%                     atom->position()[dim] += systemSize[dim];
%                 else if (atom->position()[dim] >= systemSize[dim]) 
%                     atom->position()[dim] -= systemSize[dim];
%             }
%         }
%     }
% \end{cppcode*}%
\begin{cppcode*}{gobble=4}
    void checkBoundaryConditions(System &system) {
        for (Atom *atom : system.atoms()) {
            for (int dim = 0; dim < 3; dim++) {
                if (atom->position()[dim] < 0.0) 
                    atom->position()[dim] += system.size()[dim];
                else if (atom->position()[dim] >= system.size()[dim]) 
                    atom->position()[dim] -= system.size()[dim];
            }
        }
    }
\end{cppcode*}
\caption{%
    A function for checking if any atoms have moved outside their boundaries, called \mono{checkBoundaryConditions}. This method assumes that no atoms have moved more than one system size outside the boundaries, in any direction.%
    \label{list:pbc}%
}%
\end{listing}%

A consequence of using periodic boundary conditions is that each atom now feels the force from an infinite number of atoms. To avoid having to do an infinite number of evaluations of the potential we implement something called the \emph{minimum image convention} \todobo{cite mimimum image convetion?}. This implies that we only calculate the force between atom $n$ and the \emph{nearest} image of each atom $m$, effectively limiting the potential to half the size of the system in each direction. When doing this truncation and simulating ``bulk'' or ``infinte'' systems, we do an approximation that might have some unknown consequences, but this is not usually a problem.
%\todo{really $L\sqrt{3}$, diagonally} 
%\hl{In doing this we do an approximation, but this is ok??.}

To find the distance between atom $n$ and the closest image of atom $m$ we can calculate the distance between $n$ and any image of $m$, $\rvec_{nm}$, and then check if any of the components of this vector is more than half the system size in that direction\todobo{explain why?}. See \cref{list:minimum_image_convention} for an example of a function that finds the distance between a point $u$ and the closest image of a point $v$ using the minimum image convention.%
%
\begin{listing}[!htb]%
\begin{cppcode*}{gobble=4}
    double calculateDistanceSquaredUsingMinimumImageConvention(
        const vec3 &u, const vec3 &v, 
        const vec3 &systemSize, const vec3 &halfSystemSize) {
        
        vec3 dr = u - v;
        for (int dim = 0; dim < 3; dim++) {
            if (dr[dim] >= halfSystemSize[dim]) dr -= systemSize[dim];
            else if (dr[dim] < -halfSystemSize[dim]) dr += systemSize[dim];
        }
        return dr.lengthSquared(); // Avoid calculating $\sqrt{dr^2}$, return $dr^2$ instead
    }
\end{cppcode*}
\caption{%
    An example of how to find the distance between two points \mono{u} and \mono{v} in a periodic system of size \mono{systemSize} using the \emph{minimum image convention}. We calculate the distance squared to avoid taking the square root, since this is a slow operation.%
    \label{list:minimum_image_convention}%
}%
\end{listing}%

% The use of periodic boundary conditions has some other consequences for our program. The first thing we need to consider is how to calculate the forces. In theory each atom is now affected by a force from an infinite number of numbers, since we have the image of particle $j$ in an infinte number of repeating periodic boxes. Calculating an infinite number of forces for all atoms in \hl{the periodic box} is unfeasible in a numerical experiment (in nature this infinite sum is incredibly evaluated every timestep $dt = 5.39106(32)\times 10^{-44} \text{s}$ (Planck time)), so we make an approximation where we only consider the force from atoms within the size of the box.

% \hl{force calculation unnecessary} Using the Lennard-Jones potential we see that the force from the potential decays as $1/r^{12}$, meaning that the force from most atoms will be neglible. \cref{fig:lennard-jones_potential}

\section{Optimization via force truncation\label{sec:cell_lists}}
% \todoa{Move optimizations to main md part?}
% \section{Verlet- and cell-lists\label{sec:cell_lists}}
% \todoa{What name should cell-lists have?}
\todob{We call it cell-lists, but the example program use ``box''}
If we try to simulate systems with a lot of atoms using the program we now have developed, we see that the number of evaluations of the potential quickly grow with the number of atoms, scaling as $\mathcal{O}(N^2)$. To optimize the program we can limit the number of evaluations by realizing that the Lennard-Jones potential decays as $r^{-12}$, meaning that the force between most atoms will be neglible (see \cref{fig:lennard-jones_potential} for a plot of the potential). 

From \cref{eq:lennard-jones_potential} we find that the equilibrium distance of the potential is $r_{\text{eq}} =  2^{1/6}\sigma \approx 3.8 \text{~\AA}$. We also find that the value of the potential has decreased to $21\%$ of the equilibrium value at a distance $r_{ij} =  5.5$, and to $0.5\%$ of the equilibrium value at a distance $r_{ij} =  3\sigma \approx 10.2\text{~\AA}$. From this we decide to truncate the potential at a cutoff distance $r_\text{cutoff} = 3\sigma$.

The naive implementation of this cutoff length is to do a test inside the force calculation (for example in \mono{calculateForces} in \cref{list:calculate_forces}) and see if the distance between atom $i$ and $j$ is greater than the cutoff distance, $r_{ij} > r_\text{cutoff}$. This approach this still requires the calculation of a lot of interatomic distances, so what we do instead is to implement something we call \emph{cell-lists}. This is done by dividing the system into (3d) cells of length 
\begin{align*}
    l &= L/n,
\end{align*}
where $n$ is the number of cells in a direction, which we calculate using the floor function $\lfloor x \rfloor$ as follows
\begin{align*}
    n &= \lfloor  L/r_\text{cutoff} \rfloor.
\end{align*}
Using the floor function guarantees that $l \geq r_\text{cutoff}$. 

We then only calculate the force between atom $i$ and all atoms in the cell it belongs to, and between it all atoms in the 26 neighboring cells. Since $l\geq r_\text{cutoff}$, this means that we include all atoms within a distance of at least $r_\text{cutoff}$ in the force calculations. See \cref{fig:cell_lists} for a 2-dimensional illustration of this.
\begin{figure}[htpb]%
    \centering%
    \includesvg[width=0.6\textwidth, svgpath=./images/lennard-jones/]{cell_list02}%
%     \includesvg[width=0.7\textwidth, svgpath=./images/lennard-jones/]{lennard-jones}%
%     \caption{%
%         An illustration of cell lists in 2 dimensions. We divide the system into cells of size $r \geq r_\text{cutoff}$, and calculate the force between atom $i$ and all atoms in the cell of that atom, and between that atom and all atoms in the 8 neighbor cells (26 neighbor cells in 3 dimensions). %
%         \label{fig:cell_lists}%
%     }%
    \caption{%
        An illustration of cell lists in 2 dimensions. We truncate the potential at $r_\text{cutoff}$ by only calculating the force between atom $i$ and all atoms in the cell of that atom, and between that atom and all atoms in the 8 neighbor cells (26 neighbor cells in 3 dimensions). %
        \label{fig:cell_lists}%
    }%
\end{figure}%

One issue that arises when using the cell lists is how to utilize Newton's third law. We see that after calculating the force between all atoms in cell $(i,j,k)$ and all atoms in the 26 neighboring cells, while adding the calculated forces to the other atoms using Newton's third law, we must not include that cell \hl{(cell $(i,j,k)$)} in any other force calculations this timestep, or else we will get double contributions from atoms in that cell. One simple way of solving this is to keep a list of all cells we have calculated the forces on so far, and then check against that every time we are calculating the force from a neighbor cell. But if we loop through the cells in the same order every time, we see that it would perhaps be more efficent to make a list over neighbor cells for each cell, so that we can just loop through a list of neighbors. \hl{But this is neglible compared to computing forces?}

An implementation of the calculation of forces using cell lists can be seen in \cref{list:cutoff_forcecalculation,list:sort_atoms_into_cells,list:calculateForceFromNeighborCells}. In these examples we don't use Newton's third law for optimization, to shorten the code and make the example simpler.
%
\begin{listing}[!htb]%
\begin{cppcode*}{gobble=4}
    void calculateForces(System &system) {
        ivec3 nCells;
        vector<Atom*> cells = 
            sortAtomsIntoCells(system, cutoffLength, nCells);
        
        // Loop over all cells
        for (int i = 0; i < nCells[0]; i ++)
        for (int j = 0; j < nCells[1]; j ++)
        for (int k = 0; k < nCells[2]; k ++)
        {{{
            for (Atom *atom : cells[i][j][k]) {
                atom->force() += 
                    calculateForceFromNeighborCells(
                        cells, nCells, atom, i, j, k
                    );
            }
        }}}
    }
\end{cppcode*}
\caption{%
    An example of an implementation of the force calculation \mono{calculateForces} from \cref{list:simple_md_program}, using the Lennard-Jones potential with a cutoff length for the force, and cell lists. Notice that we don't use Newton's third law, to simplify the example. %
    %Examples of how to calculate the forces using cell lists and Newton's third law are described \cref{sec:cell_lists}.%
    \label{list:cutoff_forcecalculation}%
}%
\end{listing}%
%
\begin{listing}[!htb]%
\begin{cppcode*}{gobble=4}
    vector<Atom*> sortAtomsIntoCells(
        System &system, double cutoffLength, ivec3 &nCells) {
        
        nCells = floor(system.size() / cutoffLength);
        ivec3 boxSize = system.size() / vec3(nCells);
        
        vector<Atom*> cells;
        for (Atom *atom : system.atoms()) {
            ivec3 index = floor(atom->position() / boxSize);
            cells[index[0]][index[1]][index[2]].push_back(atom);
        }
        return cells;
    }
\end{cppcode*}
\caption{%
    An example of an implementation of \mono{sortAtomsIntoCells} from \cref{list:cutoff_forcecalculation}. This listing shows how to sort atoms into cells for the cell list optimization described in \cref{sec:cell_lists}.%
    \label{list:sort_atoms_into_cells}%
}%
\end{listing}%
%
\begin{listing}[!htb]%
\begin{cppcode*}{gobble=4}
    vec3 calculateForceFromNeighborCells(
        vector<Atom*> &cells, ivec3 &nCells, Atom *atom1, 
        int i1, int j1, int k1) {
        
        vec3 force = zeros<vec3>();
        // Loop over 27 neighbor cells (including self)
        for (int di = -1; di <= 1; di++)
        for (int dj = -1; dj <= 1; dj++)
        for (int dk = -1; dk <= 1; dk++)
        {{{
            // Periodic boundary conditions
            int i2 = (i1 + di + nCells[0]) % nCells[0];
            int j2 = (j1 + dj + nCells[1]) % nCells[1];
            int k2 = (k1 + dk + nCells[2]) % nCells[2];
            
            // Loop over atoms in neighbor cell
            for (Atom *atom2 : cells[i2][j2][k2]) {
                if (atom1 == atom2) continue; // Skip i == j
                force() += calculateForceBetweenTwoAtoms(atom1, atom2);
            }
        }}}
        return force;
    }
\end{cppcode*}
\caption{%
    An example of an implementation of \mono{calculateForceFromNeighborCells} from \cref{list:cutoff_forcecalculation}. This listing shows how to calculate the force on an atom (\mono{atom1}), from the atoms in the cell it belongs to (\mono{cells[i1][j1][k1]}), and from the atoms in all 26 neighbor cells.%
    \label{list:calculateForceFromNeighborCells}%
}%
\end{listing}%

\todo[inline]{scaling of cell lists compared to regular, and Verlet lists?}
\todo[inline]{illustration of neighbor box vs. cutoff length?}
\todoc{Update lists every other timestep, $r+dr$, }
